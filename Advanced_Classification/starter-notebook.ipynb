{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6c7e849a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-11T09:24:53.643384Z",
     "start_time": "2021-06-11T09:24:53.622385Z"
    }
   },
   "source": [
    "# Classification Predict Student Solution\n",
    "\n",
    "© Explore Data Science Academy\n",
    "\n",
    "---\n",
    "### Honour Code\n",
    "\n",
    "I {**YOUR NAME, YOUR SURNAME**}, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the [EDSA honour code](https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract.\n",
    "\n",
    "### Predict Overview: Twitter Sentiment Classification Challenge\n",
    "\n",
    "The task involves developing a Machine Learning model to classify tweets based on people's beliefs regarding climate change. The dataset provided contains 43,943 tweets collected between April 27, 2015, and February 21, 2018. Each tweet is labeled with one of four classes: News, Pro, Neutral, or Anti, representing different perspectives on climate change.\n",
    "Your company has been awarded the contract to:\n",
    "\n",
    " 1. Analyse the supplied data;\n",
    " 2. Clean and transform data, including removing noise, handling missing values, and applying text preprocessing techniques like tokenization, stop-word removal, and stemming or lemmatization;\n",
    " 3. Extract relevant features from the tweet data that can contribute to the classification task;\n",
    " 4. Choose an appropriate Machine Learning algorithm for the classification task;\n",
    " 5. Train the model and evaluate using appropriate evaluation metrics such as accuracy, precision, recall, and F1 score;\n",
    " 6. Deploy to classify new, unseen tweets into the belief classes, and\n",
    " 7. Explain the inner working of the model to a non-technical audience.\n",
    "\n",
    "Formally the problem statement was given to you, the senior data scientist, by your manager via email reads as follow:\n",
    "\n",
    "> In this project you are tasked to model this classification problem, by exploring and preprocessing the data, perform feature engineering, and train a suitable Machine Learning model. The model will learn from the labeled tweets to classify new, unseen tweets into one of the belief classes accurately. The goal is to create a robust and accurate model that can provide valuable insights into people's perceptions of climate change.\n",
    " \n",
    "On top of this, she has provided you with a starter notebook containing vague explanations of what the main outcomes are. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "05600c92",
   "metadata": {},
   "source": [
    "<a id=\"cont\"></a>\n",
    "\n",
    "## Table of Contents\n",
    "<a href=#one>1. Introduction</a>\n",
    "\n",
    "<a href=#two>2. Problem Statement</a>\n",
    "\n",
    "<a href=#three>3. Importing Packages</a>\n",
    "\n",
    "<a href=#four>4. Loading Data</a>\n",
    "\n",
    "<a href=#five>5. Exploratory Data Analysis (EDA)</a>\n",
    "\n",
    "<a href=#six>6. Data Engineering</a>\n",
    "\n",
    "<a href=#seven>7. Modeling</a>\n",
    "\n",
    "<a href=#eight>8. Model Performance</a>\n",
    "\n",
    "<a href=#nine>9. Model Explanations</a>\n",
    "\n",
    "<a href=#ten>10. Conclusion</a>\n",
    "\n",
    "<a href=#eleven>11. References</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36ec3a3f",
   "metadata": {},
   "source": [
    " <a id=\"one\"></a>\n",
    "## 1. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "In today's world, climate change is a pressing global issue that has gained significant attention. Many companies are dedicated to reducing environmental impact and carbon footprints by offering sustainable and environmentally friendly products and services. To gauge public sentiment and understand how their offerings may be received, these companies require insights into people's beliefs regarding climate change.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17e35b43",
   "metadata": {},
   "source": [
    " <a id=\"two\"></a>\n",
    "## 2. Problem Statement\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "Develop a Machine Learning model to classify tweets based on people's beliefs regarding climate change. The dataset includes 43,943 tweets collected between April 27, 2015, and February 21, 2018, labeled with four classes:\n",
    "\n",
    "- News: The tweet links to factual news about climate change.\n",
    "- Pro: The tweet supports the belief of man-made climate change.\n",
    "- Neutral: The tweet neither supports nor refutes the belief of man-made climate change.\n",
    "- Anti: The tweet does not believe in man-made climate change.\n",
    "\n",
    "The objective is to create an accurate and robust model that can provide insights into public sentiment on climate change, aiding companies in understanding the reception of their environmentally friendly products and services for informed marketing strategies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "997462e2",
   "metadata": {},
   "source": [
    " <a id=\"three\"></a>\n",
    "## 3. Importing Packages\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Importing Packages ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to import, and briefly discuss, the libraries that will be used throughout your analysis and modelling. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "475dbe93",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-23T10:30:53.800892Z",
     "start_time": "2021-06-23T10:30:50.215449Z"
    }
   },
   "outputs": [],
   "source": [
    "# Libraries for data loading, data manipulation and data visulisation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "import time\n",
    "\n",
    "#Libraries for models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "#Libraries for model selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "#Libraries for measuring metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from  sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "#Library for feature selection\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "#Libraries for Natural Language processing\n",
    "import nltk\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import urllib\n",
    "# Setting global constants to ensure notebook results are reproducible\n",
    "#PARAMETER_CONSTANT = ###\n",
    "# set plot style\n",
    "sns.set()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f22a6718",
   "metadata": {},
   "source": [
    "<a id=\"four\"></a>\n",
    "## 4. Loading the Data\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Loading the data ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to load the data from the `df_train` file into a DataFrame. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbbb6c18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:49:35.311495Z",
     "start_time": "2021-06-28T08:49:35.295494Z"
    }
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "train = pd.read_csv('../resources/data/train.csv')\n",
    "#Testing data\n",
    "test = pd.read_csv('../resources/data/test_with_no_labels.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f08c6c4d",
   "metadata": {},
   "source": [
    "## 5. DATA CLEANING"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0580cd17",
   "metadata": {},
   "source": [
    "**Viewing the whole tweet for the training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d7f81b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>Worth a read whether you do or don't believe in climate change https://t.co/ggLZVNYjun https://t.co/7AFE2mAH8j</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>@AceofSpadesHQ My 8yo nephew is inconsolable. He wants to die of old age like me, but will perish in the fiery hellscape of climate change.</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @paigetweedy: no offense… but like… how do you just not believe… in global warming………</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          1   \n",
       "1          1   \n",
       "2          2   \n",
       "3          1   \n",
       "4          1   \n",
       "5          1   \n",
       "6          1   \n",
       "7          1   \n",
       "8          1   \n",
       "9          1   \n",
       "\n",
       "                                                                                                                                                    message  \\\n",
       "0              PolySciMajor EPA chief doesn't think carbon dioxide is main cause of global warming and.. wait, what!? https://t.co/yeLvcEFXkC via @mashable   \n",
       "1                                                                                            It's not like we lack evidence of anthropogenic global warming   \n",
       "2              RT @RawStory: Researchers say we have three years to act on climate change before it’s too late https://t.co/WdT0KdUr2f https://t.co/Z0ANPT…   \n",
       "3                                                       #TodayinMaker# WIRED : 2016 was a pivotal year in the war on climate change https://t.co/44wOTxTLcD   \n",
       "4                                RT @SoyNovioDeTodas: It's 2016, and a racist, sexist, climate change denying bigot is leading in the polls. #ElectionNight   \n",
       "5                                            Worth a read whether you do or don't believe in climate change https://t.co/ggLZVNYjun https://t.co/7AFE2mAH8j   \n",
       "6                                   RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R   \n",
       "7  RT @makeandmendlife: Six big things we can ALL do today to fight climate change, or how to be a climate activistÃ¢â‚¬Â¦ https://t.co/TYMLu6DbNM hÃ¢â‚¬Â¦   \n",
       "8               @AceofSpadesHQ My 8yo nephew is inconsolable. He wants to die of old age like me, but will perish in the fiery hellscape of climate change.   \n",
       "9                                                                  RT @paigetweedy: no offense… but like… how do you just not believe… in global warming………   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  \n",
       "5   425577  \n",
       "6   294933  \n",
       "7   992717  \n",
       "8   664510  \n",
       "9   260471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#displaying the message of the training data\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(train.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff875cd0",
   "metadata": {},
   "source": [
    "**Viewing the Testing data message**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54b21863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make sure that it is not alone in fighting climate change… https://t.co/O7T8rCgwDq</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re climate change and womens' rights and you have a fascist state. https://t.co/ifrm7eexpj</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate change is already here: https://t.co/yAedqcV9Ki #itstimetochange #climatechange @ZEROCO2_;..</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\r\\nPutin got to you too Jill ! \\r\\nTrump doesn't believe in climate change at all \\r\\nThinks it's s hoax</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause global warming!'\\r\\n-Sarcastic Republican</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RT @nycjim: Trump muzzles employees of several gov’t agencies in effort to suppress info on #climate change &amp;amp; the environment. https://t.co…</td>\n",
       "      <td>75639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@bmastenbrook yes wrote that in 3rd yr Comp Sci ethics part. Was told by climate change denying Lecturer that I was wrong &amp;amp; marked down.</td>\n",
       "      <td>211536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RT @climatehawk1: Indonesian farmers weather #climate change w/ conservation agriculture | @IPSNews https://t.co/1NZUCCMlYr…</td>\n",
       "      <td>569434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RT @guardian: British scientists face a ‘huge hit’ if the US cuts climate change research https://t.co/KlKQnYDXzh</td>\n",
       "      <td>315368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aid For Agriculture | Sustainable agriculture and climate change adaptation for small-scale farmers https://t.co/q7IPCP59x9 via @aid4ag</td>\n",
       "      <td>591733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                             message  \\\n",
       "0                          Europe will now be looking to China to make sure that it is not alone in fighting climate change… https://t.co/O7T8rCgwDq   \n",
       "1               Combine this with the polling of staffers re climate change and womens' rights and you have a fascist state. https://t.co/ifrm7eexpj   \n",
       "2        The scary, unimpeachable evidence that climate change is already here: https://t.co/yAedqcV9Ki #itstimetochange #climatechange @ZEROCO2_;..   \n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\r\\nPutin got to you too Jill ! \\r\\nTrump doesn't believe in climate change at all \\r\\nThinks it's s hoax   \n",
       "4                                                                 RT @FakeWillMoore: 'Female orgasms cause global warming!'\\r\\n-Sarcastic Republican   \n",
       "5   RT @nycjim: Trump muzzles employees of several gov’t agencies in effort to suppress info on #climate change &amp; the environment. https://t.co…   \n",
       "6       @bmastenbrook yes wrote that in 3rd yr Comp Sci ethics part. Was told by climate change denying Lecturer that I was wrong &amp; marked down.   \n",
       "7                       RT @climatehawk1: Indonesian farmers weather #climate change w/ conservation agriculture | @IPSNews https://t.co/1NZUCCMlYr…   \n",
       "8                                  RT @guardian: British scientists face a ‘huge hit’ if the US cuts climate change research https://t.co/KlKQnYDXzh   \n",
       "9            Aid For Agriculture | Sustainable agriculture and climate change adaptation for small-scale farmers https://t.co/q7IPCP59x9 via @aid4ag   \n",
       "\n",
       "   tweetid  \n",
       "0   169760  \n",
       "1    35326  \n",
       "2   224985  \n",
       "3   476263  \n",
       "4   872928  \n",
       "5    75639  \n",
       "6   211536  \n",
       "7   569434  \n",
       "8   315368  \n",
       "9   591733  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(test.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b1c3009f",
   "metadata": {},
   "source": [
    "**Observations**\n",
    "\n",
    "- The message had redudant features that are not necessary for EDA or modelling namely punctuations, hashtags, mentions, numbers, extra white space, web URLs, https and Twitter handles.\n",
    "- The features mentioned  does not carry significant meaning and can introduce unnecessary noise to the text. Also, this can limit tokenization. Thus, they will be removed from the message."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28fa5d7b",
   "metadata": {},
   "source": [
    "**A function of Cleaning the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c890529e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tweet(tweet):\n",
    "    \"\"\"\n",
    "    This function removes punctuation, hashtags, numbers, extra white space,\n",
    "    web URLs, https and Twitter handles from tweets. It converts everything to lowercase letters.\n",
    "\n",
    "    Args:\n",
    "    - tweet (str): The tweet to be cleaned.\n",
    "\n",
    "    Returns:\n",
    "    - str: The cleaned tweet.\n",
    "    \"\"\"\n",
    "    # Converting everything to lowercase\n",
    "    tweet = tweet.lower()\n",
    "\n",
    "    # Removal of  punctuation\n",
    "    tweet = re.sub(r\"[,.;':@#?!\\&/$]+\\ *\", ' ', tweet)\n",
    "\n",
    "    # Removal of hashtags\n",
    "    tweet = re.sub(r'#\\w*', '', tweet)\n",
    "\n",
    "    # Removal of numbers\n",
    "    tweet = re.sub(r'\\d+', '', tweet)\n",
    "\n",
    "    # Removal of whitespace in front of tweet\n",
    "    tweet = tweet.lstrip(' ')\n",
    "\n",
    "    # Removal extra whitespace\n",
    "    tweet = re.sub(r'\\s\\s+', ' ', tweet)\n",
    "\n",
    "    # Removal web URLs\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    tweet = re.sub(pattern_url, '', tweet)\n",
    "\n",
    "    # Removal web https\n",
    "    pattern_url = r'https'\n",
    "    tweet = re.sub(pattern_url, '', tweet)\n",
    "\n",
    "    # Removal Twitter handles (user mentions)\n",
    "    pattern_handles = r'@(\\w+)'\n",
    "    tweet = re.sub(pattern_handles, '', tweet)\n",
    "\n",
    "    return tweet"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1c7ec672",
   "metadata": {},
   "source": [
    "**Cleaned training dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d99af14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon dioxide is main cause of global warming and wait what  t co yelvcefxkc via mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it s not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt rawstory researchers say we have three years to act on climate change before it’s too late  t co wdtkdurf  t co zanpt…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired was a pivotal year in the war on climate change  t co wotxtlcd</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt soynoviodetodas it s and a racist sexist climate change denying bigot is leading in the polls electionnight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>worth a read whether you do or don t believe in climate change  t co gglzvnyjun  t co afemahj</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>rt thenation mike pence doesn’t believe in global warming or that smoking causes lung cancer  t co gvwyaauur</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rt makeandmendlife six big things we can all do today to fight climate change or how to be a climate activistã¢â‚¬â¦  t co tymludbnm hã¢â‚¬â¦</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>aceofspadeshq my yo nephew is inconsolable he wants to die of old age like me but will perish in the fiery hellscape of climate change</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>rt paigetweedy no offense… but like… how do you just not believe… in global warming………</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          1   \n",
       "1          1   \n",
       "2          2   \n",
       "3          1   \n",
       "4          1   \n",
       "5          1   \n",
       "6          1   \n",
       "7          1   \n",
       "8          1   \n",
       "9          1   \n",
       "\n",
       "                                                                                                                                         message  \\\n",
       "0                polyscimajor epa chief doesn t think carbon dioxide is main cause of global warming and wait what  t co yelvcefxkc via mashable   \n",
       "1                                                                                 it s not like we lack evidence of anthropogenic global warming   \n",
       "2                      rt rawstory researchers say we have three years to act on climate change before it’s too late  t co wdtkdurf  t co zanpt…   \n",
       "3                                                              todayinmaker wired was a pivotal year in the war on climate change  t co wotxtlcd   \n",
       "4                                 rt soynoviodetodas it s and a racist sexist climate change denying bigot is leading in the polls electionnight   \n",
       "5                                                  worth a read whether you do or don t believe in climate change  t co gglzvnyjun  t co afemahj   \n",
       "6                                   rt thenation mike pence doesn’t believe in global warming or that smoking causes lung cancer  t co gvwyaauur   \n",
       "7  rt makeandmendlife six big things we can all do today to fight climate change or how to be a climate activistã¢â‚¬â¦  t co tymludbnm hã¢â‚¬â¦   \n",
       "8        aceofspadeshq my yo nephew is inconsolable he wants to die of old age like me but will perish in the fiery hellscape of climate change    \n",
       "9                                                         rt paigetweedy no offense… but like… how do you just not believe… in global warming………   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  \n",
       "5   425577  \n",
       "6   294933  \n",
       "7   992717  \n",
       "8   664510  \n",
       "9   260471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the function to the training data\n",
    "train['message'] = train['message'].apply(clean_tweet)\n",
    "#displaying the message of the training data first 10 rows\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(train.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "652ea658",
   "metadata": {},
   "source": [
    "**Cleaned testing dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe2055cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn t think carbon dioxide is main cause of global warming and wait what  t co yelvcefxkc via mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>it s not like we lack evidence of anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt rawstory researchers say we have three years to act on climate change before it’s too late  t co wdtkdurf  t co zanpt…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired was a pivotal year in the war on climate change  t co wotxtlcd</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt soynoviodetodas it s and a racist sexist climate change denying bigot is leading in the polls electionnight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>worth a read whether you do or don t believe in climate change  t co gglzvnyjun  t co afemahj</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>rt thenation mike pence doesn’t believe in global warming or that smoking causes lung cancer  t co gvwyaauur</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rt makeandmendlife six big things we can all do today to fight climate change or how to be a climate activistã¢â‚¬â¦  t co tymludbnm hã¢â‚¬â¦</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>aceofspadeshq my yo nephew is inconsolable he wants to die of old age like me but will perish in the fiery hellscape of climate change</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>rt paigetweedy no offense… but like… how do you just not believe… in global warming………</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          1   \n",
       "1          1   \n",
       "2          2   \n",
       "3          1   \n",
       "4          1   \n",
       "5          1   \n",
       "6          1   \n",
       "7          1   \n",
       "8          1   \n",
       "9          1   \n",
       "\n",
       "                                                                                                                                         message  \\\n",
       "0                polyscimajor epa chief doesn t think carbon dioxide is main cause of global warming and wait what  t co yelvcefxkc via mashable   \n",
       "1                                                                                 it s not like we lack evidence of anthropogenic global warming   \n",
       "2                      rt rawstory researchers say we have three years to act on climate change before it’s too late  t co wdtkdurf  t co zanpt…   \n",
       "3                                                              todayinmaker wired was a pivotal year in the war on climate change  t co wotxtlcd   \n",
       "4                                 rt soynoviodetodas it s and a racist sexist climate change denying bigot is leading in the polls electionnight   \n",
       "5                                                  worth a read whether you do or don t believe in climate change  t co gglzvnyjun  t co afemahj   \n",
       "6                                   rt thenation mike pence doesn’t believe in global warming or that smoking causes lung cancer  t co gvwyaauur   \n",
       "7  rt makeandmendlife six big things we can all do today to fight climate change or how to be a climate activistã¢â‚¬â¦  t co tymludbnm hã¢â‚¬â¦   \n",
       "8        aceofspadeshq my yo nephew is inconsolable he wants to die of old age like me but will perish in the fiery hellscape of climate change    \n",
       "9                                                         rt paigetweedy no offense… but like… how do you just not believe… in global warming………   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  \n",
       "5   425577  \n",
       "6   294933  \n",
       "7   992717  \n",
       "8   664510  \n",
       "9   260471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the function to the testing data\n",
    "test['message'] = test['message'].apply(clean_tweet)\n",
    "#displaying the message of the testing data first 10 rows\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(train.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8aeb6942",
   "metadata": {},
   "source": [
    "**Observation**\n",
    "\n",
    "- The above dataframes are now readable, but however have stopwords that do not carry important meaning or aid much to the understanding of the message.\n",
    "- Thus, the stop words will be removed to reduce the noise, and will later help in the improvement of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "167a57d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    \"\"\"\n",
    "    This function removes stop words from the given text.\n",
    "\n",
    "    Args:\n",
    "    - text (str): The input text to be processed.\n",
    "\n",
    "    Returns:\n",
    "    - str: The text after removing stop words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Get the list of English stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text)\n",
    "\n",
    "    # Remove stop words\n",
    "    filtered_tokens = [token for token in tokens if token.lower() not in stop_words]\n",
    "\n",
    "    # Join the filtered tokens back into a string\n",
    "    filtered_text = ' '.join(filtered_tokens)\n",
    "\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7eb8f8d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide main cause global warming wait co yelvcefxkc via mashable</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt rawstory researchers say three years act climate change ’ late co wdtkdurf co zanpt…</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired pivotal year war climate change co wotxtlcd</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt soynoviodetodas racist sexist climate change denying bigot leading polls electionnight</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>worth read whether believe climate change co gglzvnyjun co afemahj</td>\n",
       "      <td>425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>rt thenation mike pence ’ believe global warming smoking causes lung cancer co gvwyaauur</td>\n",
       "      <td>294933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>rt makeandmendlife six big things today fight climate change climate activistã¢â‚¬â¦ co tymludbnm hã¢â‚¬â¦</td>\n",
       "      <td>992717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>aceofspadeshq yo nephew inconsolable wants die old age like perish fiery hellscape climate change</td>\n",
       "      <td>664510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>rt paigetweedy offense… like… believe… global warming………</td>\n",
       "      <td>260471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment  \\\n",
       "0          1   \n",
       "1          1   \n",
       "2          2   \n",
       "3          1   \n",
       "4          1   \n",
       "5          1   \n",
       "6          1   \n",
       "7          1   \n",
       "8          1   \n",
       "9          1   \n",
       "\n",
       "                                                                                                      message  \\\n",
       "0       polyscimajor epa chief think carbon dioxide main cause global warming wait co yelvcefxkc via mashable   \n",
       "1                                                             like lack evidence anthropogenic global warming   \n",
       "2                     rt rawstory researchers say three years act climate change ’ late co wdtkdurf co zanpt…   \n",
       "3                                              todayinmaker wired pivotal year war climate change co wotxtlcd   \n",
       "4                   rt soynoviodetodas racist sexist climate change denying bigot leading polls electionnight   \n",
       "5                                          worth read whether believe climate change co gglzvnyjun co afemahj   \n",
       "6                    rt thenation mike pence ’ believe global warming smoking causes lung cancer co gvwyaauur   \n",
       "7  rt makeandmendlife six big things today fight climate change climate activistã¢â‚¬â¦ co tymludbnm hã¢â‚¬â¦   \n",
       "8           aceofspadeshq yo nephew inconsolable wants die old age like perish fiery hellscape climate change   \n",
       "9                                                    rt paigetweedy offense… like… believe… global warming………   \n",
       "\n",
       "   tweetid  \n",
       "0   625221  \n",
       "1   126103  \n",
       "2   698562  \n",
       "3   573736  \n",
       "4   466954  \n",
       "5   425577  \n",
       "6   294933  \n",
       "7   992717  \n",
       "8   664510  \n",
       "9   260471  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the function to the training data\n",
    "train['message']= train['message'].apply(lambda x: remove_stopwords(x))\n",
    "#displaying the message of the training data first 10 rows\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "48d038aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>europe looking china make sure alone fighting climate change… co otrcgwdq</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>combine polling staffers climate change womens rights fascist state co ifrmeexpj</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>scary unimpeachable evidence climate change already co yaedqcvki itstimetochange climatechange zeroco_</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>karoli morgfair osborneink dailykos putin got jill trump believe climate change thinks hoax</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rt fakewillmoore female orgasms cause global warming -sarcastic republican</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rt nycjim trump muzzles employees several gov ’ agencies effort suppress info climate change amp environment co…</td>\n",
       "      <td>75639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bmastenbrook yes wrote rd yr comp sci ethics part told climate change denying lecturer wrong amp marked</td>\n",
       "      <td>211536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rt climatehawk indonesian farmers weather climate change w conservation agriculture | ipsnews co nzuccmlyr…</td>\n",
       "      <td>569434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rt guardian british scientists face ‘ huge hit ’ us cuts climate change research co klkqnydxzh</td>\n",
       "      <td>315368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>aid agriculture | sustainable agriculture climate change adaptation small-scale farmers co qipcpx via aidag</td>\n",
       "      <td>591733</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                            message  \\\n",
       "0                                         europe looking china make sure alone fighting climate change… co otrcgwdq   \n",
       "1                                  combine polling staffers climate change womens rights fascist state co ifrmeexpj   \n",
       "2            scary unimpeachable evidence climate change already co yaedqcvki itstimetochange climatechange zeroco_   \n",
       "3                       karoli morgfair osborneink dailykos putin got jill trump believe climate change thinks hoax   \n",
       "4                                        rt fakewillmoore female orgasms cause global warming -sarcastic republican   \n",
       "5  rt nycjim trump muzzles employees several gov ’ agencies effort suppress info climate change amp environment co…   \n",
       "6           bmastenbrook yes wrote rd yr comp sci ethics part told climate change denying lecturer wrong amp marked   \n",
       "7       rt climatehawk indonesian farmers weather climate change w conservation agriculture | ipsnews co nzuccmlyr…   \n",
       "8                    rt guardian british scientists face ‘ huge hit ’ us cuts climate change research co klkqnydxzh   \n",
       "9       aid agriculture | sustainable agriculture climate change adaptation small-scale farmers co qipcpx via aidag   \n",
       "\n",
       "   tweetid  \n",
       "0   169760  \n",
       "1    35326  \n",
       "2   224985  \n",
       "3   476263  \n",
       "4   872928  \n",
       "5    75639  \n",
       "6   211536  \n",
       "7   569434  \n",
       "8   315368  \n",
       "9   591733  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Applying the remove stop words function to the testing data\n",
    "test['message']= test['message'].apply(lambda x: remove_stopwords(x))\n",
    "#displaying the message of the testing data first 10 rows\n",
    "with pd.option_context('display.max_colwidth', 400):\n",
    "    display(test.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "81132ab3",
   "metadata": {},
   "source": [
    "<a id=\"five\"></a>\n",
    "## 5. Exploratory Data Analysis (EDA)\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Exploratory data analysis ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to perform an in-depth analysis of all the variables in the DataFrame. |\n",
    "\n",
    "---\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "86c6a0d0",
   "metadata": {},
   "source": [
    "**Checking the shape of the training and testing data:** The training set have three features and the testing set has two features. The Training set has 15819 observations and the testing set has 10546 Observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5298c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training data\n",
    "print(train.shape)\n",
    "#Testing data\n",
    "print(test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adb46bfe",
   "metadata": {},
   "source": [
    "**Reading the first five rows of the training data:** As elaborated by the shape, the testing dataframe have three features namely the message, sentiment and the tweetid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fce8acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the first 5 rows of test data\n",
    "train.head()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "392cc81a",
   "metadata": {},
   "source": [
    "**Reading the first five rows of the testing data:** As elaborated by the shape, the testing dataframe have two features namely the message and the tweetid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18c9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the first 5 rows of test data\n",
    "test.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c315850c",
   "metadata": {},
   "source": [
    "**DataFrame Information**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f1f808f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Checking for the datatypes, null values')\n",
    "print('')\n",
    "# Checking for the datatypes, null values\n",
    "print(train.info())\n",
    "\n",
    "print('')\n",
    "print(\"Checking the sum of null values\")\n",
    "print('')\n",
    "#Checking the sum of null values\n",
    "print(train.isnull().sum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8a0e6752",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "- By checking the infomation of the train set, it is confirmed that there are 15819 rows and 3 columns.\n",
    "- It is also observed that there are no null values present in all the columns.\n",
    "- Columns sentiment and tweetid contain numerical values, their dtype is int64. The message column contains non-numerical values, therefore it had a dtype object.\n",
    "- Moreover, the dataframe takes up the space of 721.6 kb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4506056",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_sent(sent_list):\n",
    "    sentiments_dict = {}\n",
    "    for num in sent_list:\n",
    "        if num in sentiments_dict:\n",
    "            sentiments_dict[num] += 1\n",
    "        else:\n",
    "             sentiments_dict[num] = 1\n",
    "    return  sentiments_dict  \n",
    "\n",
    "seperate_sent(train['sentiment'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d8090bc7",
   "metadata": {},
   "source": [
    "**Distribution of the Tweets over Four Sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e805134e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-28T08:52:37.824204Z",
     "start_time": "2021-06-28T08:52:37.811206Z"
    }
   },
   "outputs": [],
   "source": [
    "# Counting Number of words\n",
    "train['sentiment'].value_counts().plot(kind = 'bar')\n",
    "\n",
    "sentiments = list(seperate_sent(train['sentiment']).keys())\n",
    "numbers = list(seperate_sent(train['sentiment']).values())\n",
    "\n",
    "for i, value in enumerate(numbers):\n",
    "    plt.text(i, value, str(value), ha='center', va='bottom')\n",
    "plt.xlabel('Sentiments')\n",
    "plt.ylabel('Number of Tweets')\n",
    "plt.title('Distribution of tweets over the four sentiments')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5be5792d",
   "metadata": {},
   "source": [
    "**Observations:**\n",
    "\n",
    "1. There are 8530 tweets for sentiment 1, 3640 tweets for sentiment 2, 2353 tweets for sentiment 0 and 1296 tweets for sentiment -1. \n",
    "2. There is data imbalance, those who supports man-made climate change make up half of all the tweets and those who are against the matter makes up only 8% of the entire tweets. \n",
    "3. There are many tweets from those who believe in man-made Climate change because those supports man made climate change are well versed about the matter and also, they easily share their views because they are more interested in the matter.\n",
    "4. However, those who are against the notion may be skeptical due to personal beliefs which can lead to a reluctance to engage in discussions about man-made climate change. Also, those who do not believe in the matter may not have enough information to support their stance. \n",
    "5. The data imbalanced can be solved by resampling in order to improve Model Performance, Address Data Skewness, Preserve Information and mitigate Model Bias."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cabec441",
   "metadata": {},
   "source": [
    "**Distribution of the number of characters on each tweets for the four sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d17bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a number of Sentences features\n",
    "train['num_sentences'] = train['message'].apply(lambda x:len(nltk.sent_tokenize(x)))\n",
    "\n",
    "# Create a 2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Plot histogram for sentiment category 0\n",
    "sns.histplot(train[train['sentiment'] == 0]['num_sentences'], ax=axes[0, 0])\n",
    "\n",
    "# Plot histogram for sentiment category 1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 1]['num_sentences'], color='red', ax=axes[0, 1])\n",
    "\n",
    "# Plot histogram for sentiment category -1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == -1]['num_sentences'], color='green', ax=axes[1, 0])\n",
    "\n",
    "# Plot histogram for sentiment category -2 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 2]['num_sentences'], color='purple', ax=axes[1, 1])\n",
    "\n",
    "# Set the title for each subplot\n",
    "axes[0, 0].set_title('Sentiment Category 0')\n",
    "axes[0, 1].set_title('Sentiment Category 1')\n",
    "axes[1, 0].set_title('Sentiment Category -1')\n",
    "axes[1, 1].set_title('Sentiment Category 2')\n",
    "\n",
    "# Adjust the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the subplots\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ee24f389",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "\n",
    "1. The news have a range of 1 to 4 number of sentences. Those who are neutral and those who are against the matter have a range of 1 to 6 sentences. However, those whose who supports man-made climate has a range of 1 to 11 sentences.\n",
    "2. Those who supports the matters have outliers who might have a deeper understanding of the topic due to personal experiences, research, or education. Consequently, they may feel more confident and knowledgeable, resulting in more extensive and well-articulated responses."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb38ff08",
   "metadata": {},
   "source": [
    "**Distribution of the Number of Words on each tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89eeff91",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a number of Words feature\n",
    "train['num_words'] =train['message'].apply(lambda x:len(nltk.word_tokenize(x)))\n",
    "\n",
    "# A2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "# Histogram for sentiment category 0\n",
    "sns.histplot(train[train['sentiment'] == 0]['num_words'], ax=axes[0, 0])\n",
    "\n",
    "# Histogram for sentiment category 1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 1]['num_words'], color='red', ax=axes[0, 1])\n",
    "\n",
    "#Histogram for sentiment category -1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == -1]['num_words'], color='green', ax=axes[1, 0])\n",
    "\n",
    "#Histogram for sentiment category 2 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 2]['num_words'], color='purple', ax=axes[1, 1])\n",
    "\n",
    "#Titles for each subplot\n",
    "axes[0, 0].set_title('Sentiment Category 0')\n",
    "axes[0, 1].set_title('Sentiment Category 1')\n",
    "axes[1, 0].set_title('Sentiment Category -1')\n",
    "axes[1, 1].set_title('Sentiment Category 2')\n",
    "\n",
    "# Adjusting the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the subplots\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b20d294",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "\n",
    "1. The word count of the news range from 8 to 34 words, With the frequent words count of 22 words per tweet. The word count for those who are neutral range from 2 to 39 words, with the frequent words count of 26 words per tweet.The word count of who are against man made climate change range from 6 to 49 words, with the frequent word counts of 27 words per tweet. The word count of those who supports man made climate change range from 4 to 45 words, with frequent word count of 26 words per tweet.\n",
    "\n",
    "2. Those who are supports man-made climate change and those who are against climate change have wide range of word counts compared to the neutral and News sentiment. Those individuals have strong emotions and beliefs associated with it. They felt compelled to express their opinions, arguments, and concerns in more detail, resulting in the use of many words. They felt a greater need to persuade others or defend their position, leading them to provide more extensive justifications and evidence to support their viewpoint.   This is beacause People who are against or support the  matter often face resistance and criticism. In response, they might employ more words to address potential counterarguments, clarify their stance, or counter opposing viewpoints.\n",
    "\n",
    "*Need attention for revision*\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63ac12ca",
   "metadata": {},
   "source": [
    "**Distribution of the Number of Characters on each tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28282ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a number of characters feature\n",
    "train['num_characters'] = train['message'].apply(len)\n",
    "\n",
    "#A 2x2 grid of subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(10, 8))\n",
    "\n",
    "#Histogram for sentiment category 0\n",
    "sns.histplot(train[train['sentiment'] == 0]['num_characters'], ax=axes[0, 0])\n",
    "\n",
    "#Histogram for sentiment category 1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 1]['num_characters'], color='red', ax=axes[0, 1])\n",
    "\n",
    "#Histogram for sentiment category -1 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == -1]['num_characters'], color='green', ax=axes[1, 0])\n",
    "\n",
    "#Histogram for sentiment category 2 (with a different color)\n",
    "sns.histplot(train[train['sentiment'] == 2]['num_characters'], color='purple', ax=axes[1, 1])\n",
    "\n",
    "#The title for each subplot\n",
    "axes[0, 0].set_title('Sentiment Category 0')\n",
    "axes[0, 1].set_title('Sentiment Category 1')\n",
    "axes[1, 0].set_title('Sentiment Category -1')\n",
    "axes[1, 1].set_title('Sentiment Category 2')\n",
    "\n",
    "# Adjusting the spacing between subplots\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the subplots\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99ee5997",
   "metadata": {},
   "source": [
    "**Observation:** \n",
    "\n",
    "1. All the sentement has a mode of 140 characters. Research has shown that initially twitter had a strict limit of 140 characters per tweet. Thus, this was one of the constraints which might have led to most individuals writing tweets with 140 chracaters though they wanted to write even more words. \n",
    "2. However, the constraints was later increased to 280, this has enable some individuals to fit their thoughts since the graphs above show no indication of a tweet with more than 280 characters. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "32d9d8fd",
   "metadata": {},
   "source": [
    "**Removing Stopwords**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb74182",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download(['punkt','stopwords'])\n",
    "\n",
    "#A function of removing stopwords\n",
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = text.split()\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return ' '.join(filtered_tokens)\n",
    "#Removing stop words from training data\n",
    "train['updated message'] = train['message'].apply(remove_stopwords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "16fecb5d",
   "metadata": {},
   "source": [
    "**Removing punctuation Marks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308fcbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A fucntion of removing puntuationa marks\n",
    "def remove_punctuation(post):\n",
    "    return ''.join([l for l in post if l not in string.punctuation])\n",
    "\n",
    "# Create and Check if a new column contains messages with no punctuations\n",
    "train['updated message'] = train['updated message'].apply(remove_punctuation).str.lower() #Words converted to lower case\n",
    "train['updated message'].iloc[0]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "88c5f925",
   "metadata": {},
   "source": [
    "**Masking the four sentiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a8adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tweets of those who believe in Climate change\n",
    "pro = train.loc[train['sentiment'] == 1, 'updated message']\n",
    "#Tweets of those dont believe in climate change\n",
    "anti = train.loc[train['sentiment'] == -1, 'updated message']\n",
    "#Tweets of those are neautral about climate change\n",
    "neutral = train.loc[train['sentiment'] == 0, 'updated message']\n",
    "##Tweets of the news\n",
    "news = train.loc[train['sentiment'] == 2, 'updated message']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d9be275e",
   "metadata": {},
   "source": [
    "**Word Clouds of the top fifty Words that appear the most from each sentiment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2d443c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the categories and their respective texts\n",
    "categories = ['Pro', 'Anti', 'Neutral', 'News']\n",
    "texts = [pro, anti, neutral, news]\n",
    "\n",
    "# Create subplots\n",
    "fig, axs = plt.subplots(2, 2, figsize=(12, 9))\n",
    "fig.subplots_adjust(hspace=0)  # Adjust the hspace parameter to remove vertical spacing\n",
    "\n",
    "# Generate word clouds for each category and plot them\n",
    "for i, ax in enumerate(axs.flat):\n",
    "    # Calculate word distribution\n",
    "    text = ' '.join(texts[i])\n",
    "    words = text.split()\n",
    "    word_counts = Counter(words)\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(max_words=50)\n",
    "    wordcloud.generate_from_frequencies(word_counts)\n",
    "    \n",
    "    # Plot the word cloud\n",
    "    ax.imshow(wordcloud, interpolation='bilinear')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(categories[i])\n",
    "\n",
    "# Show the subplots\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f7dc2c48",
   "metadata": {},
   "source": [
    "## Observations:\n",
    "\n",
    "1. From the cloud words above, it is observed that climate, change, global and warming are the most popular words that are used by individuals, this is expected since the topic revolves around these words.  \n",
    "2. Those who support the matter use the word believe more than those who don't against the matter. Also, they also use the word going and die which doesnt appear on the word cloud of those against climate change.\n",
    "3. People who are against the man-made Climate change use words like Fake and scam to show their resistance in the man made climate change. Moreover, they use hoax more often than those who support man-made climate change. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "20b79668",
   "metadata": {},
   "source": [
    "**Ayanda**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0db7e2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fa93ec6",
   "metadata": {},
   "source": [
    "<a id=\"six\"></a>\n",
    "## 6. Data Engineering\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Data engineering ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to: clean the dataset, and possibly create new features - as identified in the EDA phase. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e56b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cba12d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb563629",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d989735",
   "metadata": {},
   "source": [
    "**Palesa**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2394cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "589bdfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60d1d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d64c098",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0e4c51e",
   "metadata": {},
   "source": [
    "**Shibu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2bc5a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aae777d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c93078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daab7378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15a4489d",
   "metadata": {},
   "source": [
    "**Lebo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e88cc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedf7f2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3105579b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "112d0c6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0ac57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View the data after EDA\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c2f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove missing values/ features\n",
    "# Remove the column message\n",
    "train = train.drop('message', axis = 1)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84eea17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create new features\n",
    "Pro = train[train['sentiment'] == 1]\n",
    "Anti = train[train['sentiment'] == -1]\n",
    "Neutral = train[train['sentiment'] == 0]\n",
    "News = train[train['sentiment'] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59692724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# engineer existing features\n",
    "for word in "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "43b2d523",
   "metadata": {},
   "source": [
    "<a id=\"seven\"></a>\n",
    "## 7. Modelling\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Modelling ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to create one or more regression models that are able to accurately predict the thee hour load shortfall. |\n",
    "\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da79ca4a",
   "metadata": {},
   "source": [
    "**Tshifhu**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96c7abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Logistic Regression', 'Nearest Neighbors',\n",
    "         'RBF SVM',\n",
    "         'Decision Tree', 'Random Forest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433df6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    KNeighborsClassifier(10),\n",
    "    SVC(kernel=\"rbf\", gamma=2, C=0.025),\n",
    "    DecisionTreeClassifier(max_depth=3, min_samples_split=2),\n",
    "    RandomForestClassifier(n_estimators=100, max_depth=3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d32d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_train = []\n",
    "results_test=[]\n",
    "\n",
    "models = {}\n",
    "confusion = {}\n",
    "class_report = {}\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "\n",
    "    #Fitting the models and recording the time\n",
    "    run_time = %timeit -q -o clf.fit(X_train, y_train)\n",
    "\n",
    "    #Start time\n",
    "    start_time = time.time()\n",
    "    #Predicting on y_train using X_train\n",
    "    y_pred = clf.predict(X_train)\n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    #Execution Time\n",
    "    train_execution_time = end_time - start_time\n",
    "\n",
    "    #Start time\n",
    "    start_time = time.time()\n",
    "    #Predicting on y_train using X_train\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    #End time\n",
    "    end_time = time.time()\n",
    "    #Execution Time\n",
    "    test_execution_time = end_time - start_time\n",
    "\n",
    "    #Calculating the accuracy score of the training data\n",
    "    accuracy_train = accuracy_score(y_train, y_pred)\n",
    "    #Calculating the precision score of the training data\n",
    "    precision_train = precision_score(y_train, y_pred, average='micro')\n",
    "    #Calculating the recall score of the training data\n",
    "    recall_train = recall_score(y_train, y_pred, average='micro')\n",
    "    #Calculating the f1 score of the training data\n",
    "    f1_train = f1_score(y_train, y_pred, average='micro')\n",
    "\n",
    "\n",
    "    #Calculating the accuracy score of the testing data\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    #Calculating the precision score of the testing data\n",
    "    precision_test = precision_score(y_test, y_pred_test, average='micro')\n",
    "    #Calculating the recall score of the testing data\n",
    "    recall_test = recall_score(y_test, y_pred_test, average='micro')\n",
    "    #Calculating the F1 score of the testing data\n",
    "    f1_test   = f1_score(y_test, y_pred_test, average='micro')\n",
    "\n",
    "    # Save the results to dictionaries\n",
    "    models[name]=clf\n",
    "    #Confusion on the training data\n",
    "    confusion[name] = confusion_matrix(y_train, y_pred)\n",
    "    #Confusion on testing data\n",
    "    confusion[name] = confusion_matrix(y_test, y_pred_test)\n",
    "    #Classification report of the training data\n",
    "    class_report[name] = classification_report(y_train, y_pred)\n",
    "    #Classification report of the testing data\n",
    "    class_report[name] = classification_report(y_test, y_pred_test)\n",
    "\n",
    "    # Appending the name of the model, training data  results and fitting time of each model\n",
    "    results_train.append([name, accuracy_train, precision_train, recall_train, f1_train, run_time.best, test_execution_time])\n",
    "    # Appending the name of the model and  testing data  results\n",
    "    results_test.append([name, accuracy_test, precision_test, recall_test, f1_test, train_execution_time])\n",
    "\n",
    "#Converting the training results to a dataframe\n",
    "results_train= pd.DataFrame(results_train, columns=['Classifier', 'Accuracy Train', 'Precision Train', 'Recall', 'F1 Train', 'Train Time', 'predicting time'])\n",
    "results_train.set_index('Classifier', inplace= True)\n",
    "\n",
    "#Converting the Testing data into a Dataframe\n",
    "results_test= pd.DataFrame(results_test, columns=['Classifier', 'Accuracy Test', 'Precision  Test', 'Recall  Test', 'F1 Test', \"Predicting time\" ])\n",
    "results_test.set_index('Classifier', inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2344b3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c58df02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create targets and features dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create one or more ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70c15d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate one or more ML models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b530251",
   "metadata": {},
   "source": [
    "<a id=\"eight\"></a>\n",
    "## 8. Model Performance\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model performance ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section you are required to compare the relative performance of the various trained ML models on a holdout dataset and comment on what model is the best and why. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69b5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3874a7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model and motivate why it is the best choice"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a8ad0c0d",
   "metadata": {},
   "source": [
    "<a id=\"nine\"></a>\n",
    "## 9. Model Explanations\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>\n",
    "\n",
    "---\n",
    "    \n",
    "| ⚡ Description: Model explanation ⚡ |\n",
    "| :--------------------------- |\n",
    "| In this section, you are required to discuss how the best performing model works in a simple way so that both technical and non-technical stakeholders can grasp the intuition behind the model's inner workings. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff741c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discuss chosen methods logic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "66a5b2d4",
   "metadata": {},
   "source": [
    "<a id=\"ten\"></a>\n",
    "## 10. Conclusion\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "404edae3",
   "metadata": {},
   "source": [
    "<a id=\"eleven\"></a>\n",
    "## 11. References\n",
    "<a class=\"anchor\" id=\"1.1\"></a>\n",
    "<a href=#cont>Back to Table of Contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aecd59b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a8563",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
